{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0f6dcf",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa7f9d",
   "metadata": {},
   "source": [
    "## Load module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b67c38",
   "metadata": {},
   "source": [
    "## Define parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3acfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = (3, 224, 224)  # PyTorch expects (C, H, W)\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310ca4f",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7130c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "base_path = 'D:\\Programming_File\\Tensorflow_Files'\n",
    "train_path = 'datasets/train_set'\n",
    "val_path = 'datasets/val_set'\n",
    "train_dir = os.path.join(base_path, train_path)\n",
    "val_dir = os.path.join(base_path, val_path)\n",
    "target_size = (64, 64)  # height, width in torchvision is (H, W)\n",
    "\n",
    "print(f\"Train directory exists: {train_dir}\") if(os.path.exists(train_dir)) else print(f\"Train directory does not exist: {train_dir}\")\n",
    "print(f\"Validation directory exists: {val_dir}\") if (os.path.exists(val_dir)) else print(f\"Validation directory does not exist: {val_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118355ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e605cf2",
   "metadata": {},
   "source": [
    "## Load pre-trained ResNet50 without top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "# Remove the final classification layer\n",
    "num_ftrs = base_model.fc.in_features\n",
    "base_model.fc = nn.Identity()  # no final fc, outputs feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff73de1",
   "metadata": {},
   "source": [
    "## Freeze base model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83cb50",
   "metadata": {},
   "source": [
    "## Add custom classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a739c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferResNet50(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(num_ftrs, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()  # for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2965b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransferResNet50(base_model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a87c6",
   "metadata": {},
   "source": [
    "## Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3117e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cd93f",
   "metadata": {},
   "source": [
    "## Training loop with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "If you simply did:\n",
    "    best_model_wts = model.state_dict()\n",
    "Then, best_model_wts would point to the same memory as the model’s parameters.\n",
    "\"\"\"\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "model_path = \"transfer_resnet50_model.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.float().to(device)  # float for BCELoss\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = (outputs > 0.5).long()\n",
    "        running_corrects += torch.sum(preds == labels.long())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            preds = (outputs > 0.5).long()\n",
    "            val_corrects += torch.sum(preds == labels.long())\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = val_corrects.double() / len(val_dataset)\n",
    "    print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"✅ Best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict().keys())\n",
    "# dict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef25b8e",
   "metadata": {},
   "source": [
    "## Load best weights after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd106dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77c20f",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Data augmentation =====\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('./datasets/train_set', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder('./datasets/val_set', transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ===== Base model (ResNet50 without top) =====\n",
    "base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "for param in base_model.parameters():  # freeze\n",
    "    param.requires_grad = False\n",
    "num_ftrs = base_model.fc.in_features\n",
    "\n",
    "# ===== Build new model like Sequential in Keras =====\n",
    "model = nn.Sequential(\n",
    "    base_model,\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(num_ftrs, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "# ===== Loss & optimizer =====\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ===== Training loop =====\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch+1}/10\")\n",
    "\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0.0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x).squeeze()\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        train_correct += ((preds > 0.5).long() == y.long()).sum().item()\n",
    "\n",
    "    train_acc = train_correct / len(train_dataset)\n",
    "    print(f\"Train Loss: {train_loss/len(train_dataset):.4f} Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.float().to(device)\n",
    "            preds = model(x).squeeze()\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_correct += ((preds > 0.5).long() == y.long()).sum().item()\n",
    "\n",
    "    val_acc = val_correct / len(val_dataset)\n",
    "    print(f\"Val Loss: {val_loss/len(val_dataset):.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ===== Save best model =====\n",
    "torch.save(model.state_dict(), \"transfer_resnet50_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-py311",
   "language": "python",
   "name": "torch-py311"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
